#!/usr/bin/env python
# find duplicates
import os, sys

from collections import defaultdict
from hashlib import md5

d = defaultdict(list)

def go(path):
    if os.path.isdir(path):
        for name in os.listdir(path):
            go(os.path.join(path, name))
    else:
        with open(path) as f:
            d[md5(f.read()).hexdigest()].append(path)
            f.close()

for arg in sys.argv[1:]:
    go(arg)

for md5sum, paths in d.items():
    if len(paths) > 1:
        for path in paths:
            print md5sum, path
